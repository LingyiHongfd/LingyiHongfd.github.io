# üìù Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2024</div><img src='images/publication/compresstracker/compresstracker.png' alt="sym" width="100%"></div></div>

<!-- <div class='paper-box'><div class='paper-box-image'><div><img src='images/publication/lvos/lvos.png' alt="sym" width="100%"></div></div> -->

<div class='paper-box-text' markdown="1">

[General Compression Framework for Efficient Transformer Object Tracking](https://arxiv.org/abs/2409.17564)

**Lingyi Hong**, Jinglun Li, Xinyu Zhou, Shilin Yan, Pinxue Guo, Kaixun Jiang, Zhaoyu Chen, Shuyong Gao, Wei Zhang, Hong Lu, Wenqiang Zhang

[[**Paper**](https://arxiv.org/pdf/2409.17564.pdf)<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>]

- **General** compression framework for efficient SOT.
- Support _any_ teacher and student structure, _any_ input resolution, and _any_ layer numbers.
- Balance between efficiency and effectiveness (2.17 x speed up with 96% accuracy).
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2024 & ICCV 2023</div><img src='images/publication/lvos/lvos.png' alt="sym" width="100%"></div></div>

<div class='paper-box-text' markdown="1">

[LVOS: A Benchmark for Large-scale Long-term Video Object Segmentation](https://arxiv.org/abs/2404.19326)

**Lingyi Hong**, Zhongying Liu, Wenchao Chen, Chenzhi Tan, Yuang Feng, Xinyu Zhou, Pinxue Guo, Jinglun Li, Zhaoyu Chen, Shuyong Gao, Wei Zhang, Wenqiang Zhang


[LVOS: A Benchmark for Long-term Video Object Segmentation](https://arxiv.org/abs/2211.10181)

**Lingyi Hong**, Wenchao Chen, Zhongying Liu, Wei Zhang, Pinxue Guo, Zhaoyu Chen, Wenqiang Zhang

[[**Paper V2**](https://arxiv.org/pdf/2404.19326)<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>]
[[**Paper V1**](https://arxiv.org/pdf/2211.10181.pdf)<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>]
[[**Home Page**](https://lingyihongfd.github.io/lvos.github.io/)<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>]
[[**Github**](https://github.com/LingyiHongfd/LVOS)<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>]

- The **first** long-term video object segmentation benchmark.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024 Highlight</div><img src='images/publication/onetracker/onetracker.png' alt="sym" width="100%"></div></div>

<!-- <div class='paper-box'><div class='paper-box-image'><div><img src='images/publication/lvos/lvos.png' alt="sym" width="100%"></div></div> -->

<div class='paper-box-text' markdown="1">

<span style="color:red">(Highlight)</span> [OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning](https://arxiv.org/abs/2403.09634)

**Lingyi Hong**, Shilin Yan, Renrui Zhang, Wanyun Li, Xinyu Zhou, Pinxue Guo, Kaixun Jiang, Yiting Chen, Jinglun Li, Zhaoyu Chen, Wenqiang Zhang

[[**Paper**](https://arxiv.org/pdf/2403.09634.pdf)<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>]

- The **first** one to unify RGB and RGB+X tracking in a general framework.
- Introduce the foundation model and parameter-efficient tuning manner into object tracking and break traditional full finetuning stragety.
- SOTA performance on 6 tracking task 11 benchmarks.
</div>
</div>

- ``ICLR 2025`` [DynaPrompt: Dynamic Test-Time Prompt Tuning](https://arxiv.org/abs/2501.16404), 
Zehao Xiao, Shilin Yan, **Jack Hong**, Jiayin Cai, Xiaolong Jiang, Yao Hu, Jiayi Shen, Qi Wang, Cees GM Snoek

- ``NeurIPS 2024`` [DeTrack: In-model Latent Denoising Learning for Visual Object Tracking](https://arxiv.org/abs/2501.02467), 
Xinyu Zhou, Jinglun Li, **Lingyi Hong**, Kaixun Jiang, Pinxue Guo, Weifeng Ge, Wenqiang Zhang

- ``ACM MM 2024`` [X-prompt: Multi-modal visual prompt for video object segmentation](https://arxiv.org/abs/2409.19342), 
Pinxue Guo, Wanyun Li, Hao Huang, **Lingyi Hong**, Xinyu Zhou, Zhaoyu Chen, Jinglun Li, Kaixun Jiang, Wei Zhang, Wenqiang Zhang

- ``ACM MM 2024`` [TagOOD: A Novel Approach to Out-of-Distribution Detection via Vision-Language Representations and Class Center Learning](https://arxiv.org/abs/2408.15566), 
Jinglun Li, Xinyu Zhou, Kaixun Jiang, **Lingyi Hong**, Pinxue Guo, Zhaoyu Chen, Weifeng Ge, Wenqiang Zhang

- ``ECCV 2024`` [OneVOS: Unifying Video Object Segmentation with All-in-One Transformer Framework](https://arxiv.org/abs/2403.08682), 
Wanyun Li, Pinxue Guo, Xinyu Zhou, **Lingyi Hong**, Yangji He, Xiangyu Zheng, Wei Zhang, Wenqiang Zhang

- ``ECCV 2024`` [PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation](https://arxiv.org/abs/2309.12303), 
Shilin Yan, Xiaohao Xu, Renrui Zhang, **Lingyi Hong**, Wenchao Chen, Wenqiang Zhang, Wei Zhang

- ``NeurIPS 2023`` [Reading Relevant Feature from Global Representation Memory for Visual Object Tracking](https://arxiv.org/abs/2402.14392), 
Xinyu Zhou, Pinxue Guo, **Lingyi Hong**, Jinglun Li, Wei Zhang, Weifeng Ge, Wenqiang Zhang


- ``ACM MM 2023`` [SimulFlow: Simultaneously Extracting Feature and Identifying Target for Unsupervised Video Object Segmentation](https://arxiv.org/abs/2311.18286), **Lingyi Hong**, Wei Zhang, Shuyong Gao, Hong Lu, WenQiang Zhang

- ``ACM MM 2023`` [Exploring the Adversarial Robustness of Video Object Segmentation via One-shot Adversarial Attacks](https://dl.acm.org/doi/abs/10.1145/3581783.3611827), Kaixun Jiang, **Lingyi Hong**, Zhaoyu Chen, Pinxue Guo, Zeng Tao, Yan Wang, Wenqiang Zhang

- ``ACM MM 2023`` <span style="color:red">(Oral)</span> [Towards Decision-based Sparse Attacks on Video Recognition](https://dl.acm.org/doi/abs/10.1145/3581783.3611828), Kaixun Jiang, Zhaoyu Chen, Xinyu Zhou, Jingyu Zhang, **Lingyi Hong**, JiaFeng Wang, Bo Li, Yan Wang, Wenqiang Zhang